 # PROJECT AIMS
 
 The aim of this study is to find the possibilities of using Deep Neural Network (DNN) for translating sign languages into speech and text format through human hand gestures.
 
 The main objective of this study is to explore the feasibility of introducing a vision-based application,
 for the translation of the sign language to eradicate communication barriers between the hearing
 blind and deaf communities, sign language is translated into a text and speech format by recognizing sign signs
 The system has been developed following the training of a pre-trained SSD-Network using the captured dataset
 This system could be researched further and analyze the different types of sign language vocabulary and improve the interface aspect.

